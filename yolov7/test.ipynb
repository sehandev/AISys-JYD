{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import coco80_to_coco91_class, check_dataset, check_file, check_img_size, check_requirements, \\\n",
    "    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr\n",
    "from utils.metrics import ap_per_class, ConfusionMatrix\n",
    "from utils.plots import plot_images, output_to_target, plot_study_txt\n",
    "from utils.torch_utils import select_device, time_synchronized, TracedModel\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "sys.path.append('./')  # to run '$ python *.py' files in subdirectories\n",
    "logger = logging.getLogger(__name__)\n",
    "import torch\n",
    "from models.common import *\n",
    "from models.experimental import *\n",
    "from utils.autoanchor import check_anchor_order\n",
    "from utils.general import make_divisible, check_file, set_logging\n",
    "from utils.torch_utils import time_synchronized, fuse_conv_and_bn, model_info, scale_img, initialize_weights, \\\n",
    "    select_device, copy_attr\n",
    "from utils.loss import SigmoidBin\n",
    "from models.yolo import *\n",
    "try:\n",
    "    import thop  # for FLOPS computation\n",
    "except ImportError:\n",
    "    thop = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augment=False, batch_size=32, conf_thres=0.001, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights='yolov7.pt')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(prog='test.py')\n",
    "    parser.add_argument('--weights', nargs='+', type=str, default='yolov7.pt', help='model.pt path(s)')\n",
    "    parser.add_argument('--data', type=str, default='data/coco.yaml', help='*.data path')\n",
    "    parser.add_argument('--batch-size', type=int, default=32, help='size of each image batch')\n",
    "    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n",
    "    parser.add_argument('--conf-thres', type=float, default=0.001, help='object confidence threshold')\n",
    "    parser.add_argument('--iou-thres', type=float, default=0.65, help='IOU threshold for NMS')\n",
    "    parser.add_argument('--task', default='val', help='train, val, test, speed or study')\n",
    "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--single-cls', action='store_true', help='treat as single-class dataset')\n",
    "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
    "    parser.add_argument('--verbose', action='store_true', help='report mAP by class')\n",
    "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
    "    parser.add_argument('--save-hybrid', action='store_true', help='save label+prediction hybrid results to *.txt')\n",
    "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
    "    parser.add_argument('--save-json', action='store_true', help='save a cocoapi-compatible JSON results file')\n",
    "    parser.add_argument('--project', default='runs/test', help='save to project/name')\n",
    "    parser.add_argument('--name', default='exp', help='save to project/name')\n",
    "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
    "    parser.add_argument('--no-trace', action='store_true', help='don`t trace model')\n",
    "    parser.add_argument('--v5-metric', action='store_true', help='assume maximum recall as 1.0 in AP calculation')\n",
    "    opt = parser.parse_args([])\n",
    "    opt.save_json |= opt.data.endswith('coco.yaml')\n",
    "    opt.data = check_file(opt.data)  # check file\n",
    "    print(opt)\n",
    "    #check_requirements()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'imgsz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_748/1958231442.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'imgsz'"
     ]
    }
   ],
   "source": [
    "1, 3, opt.imgsz, opt.imgsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "       0.0       928       2.1ms models.common.Conv                      \n",
      "       0.0     18560       1.4ms models.common.Conv                      \n",
      "       0.0     36992       1.5ms models.common.Conv                      \n",
      "       0.0     73984       0.7ms models.common.Conv                      \n",
      "       0.0      8320       0.1ms models.common.Conv                      \n",
      "       0.0      8320       0.1ms models.common.Conv                      \n",
      "       0.0     36992       0.3ms models.common.Conv                      \n",
      "       0.0     36992       0.3ms models.common.Conv                      \n",
      "       0.0     36992       0.3ms models.common.Conv                      \n",
      "       0.0     36992       0.3ms models.common.Conv                      \n",
      "       0.0         0       0.2ms models.common.Concat                    \n",
      "       0.0     66048       1.0ms models.common.Conv                      \n",
      "       0.0         0       0.1ms models.common.MP                        \n",
      "       0.0     33024       0.1ms models.common.Conv                      \n",
      "       0.0     33024       0.5ms models.common.Conv                      \n",
      "       0.0    147712       0.3ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0     33024       0.1ms models.common.Conv                      \n",
      "       0.0     33024       0.1ms models.common.Conv                      \n",
      "       0.0    147712       0.2ms models.common.Conv                      \n",
      "       0.0    147712       0.2ms models.common.Conv                      \n",
      "       0.0    147712       0.2ms models.common.Conv                      \n",
      "       0.0    147712       0.2ms models.common.Conv                      \n",
      "       0.0         0       0.1ms models.common.Concat                    \n",
      "       0.0    263168       0.6ms models.common.Conv                      \n",
      "       0.0         0       0.1ms models.common.MP                        \n",
      "       0.0    131584       0.1ms models.common.Conv                      \n",
      "       0.0    131584       0.3ms models.common.Conv                      \n",
      "       0.0    590336       0.2ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0    131584       0.1ms models.common.Conv                      \n",
      "       0.0    131584       0.1ms models.common.Conv                      \n",
      "       0.0    590336       0.2ms models.common.Conv                      \n",
      "       0.0    590336       0.2ms models.common.Conv                      \n",
      "       0.0    590336       0.2ms models.common.Conv                      \n",
      "       0.0    590336       0.2ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0   1050624       0.4ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.MP                        \n",
      "       0.0    525312       0.1ms models.common.Conv                      \n",
      "       0.0    525312       0.2ms models.common.Conv                      \n",
      "       0.0   2360320       0.3ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0    262656       0.1ms models.common.Conv                      \n",
      "       0.0    262656       0.1ms models.common.Conv                      \n",
      "       0.0    590336       0.1ms models.common.Conv                      \n",
      "       0.0    590336       0.1ms models.common.Conv                      \n",
      "       0.0    590336       0.1ms models.common.Conv                      \n",
      "       0.0    590336       0.1ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0   1050624       0.1ms models.common.Conv                      \n",
      "       0.0   7609344       1.6ms models.common.SPPCSPC                   \n",
      "       0.0    131584       0.0ms models.common.Conv                      \n",
      "before 15.7ms total\n"
     ]
    }
   ],
   "source": [
    "profile = True\n",
    "y, dt = [], []  # outputs\n",
    "\n",
    "\n",
    "device = select_device(\"cpu\", batch_size=opt.batch_size)\n",
    "model = attempt_load(opt.weights, map_location=device)  # load FP32 model\n",
    "model.eval()\n",
    "\n",
    "opt.imgsz=640\n",
    "imgsz=640\n",
    "x = torch.zeros(1, 3, opt.imgsz, opt.imgsz).to(device).type_as(next(model.parameters()))\n",
    "\n",
    "\n",
    "## client inference\n",
    "\n",
    "\n",
    "for m in model.model[:len(model.model)//2]:\n",
    "    # print(m)\n",
    "    if m.f != -1:  # if not from previous layer\n",
    "        x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
    "\n",
    "    if profile:\n",
    "        c = isinstance(m, (Detect, IDetect, IAuxDetect, IBin))\n",
    "        o = thop.profile(m, inputs=(x.copy() if c else x,), verbose=False)[0] / 1E9 * 2 if thop else 0  # FLOPS\n",
    "        for _ in range(10):\n",
    "            m(x.copy() if c else x)\n",
    "        t = time_synchronized()\n",
    "        # for _ in range(10):\n",
    "        #     m(x.copy() if c else x)\n",
    "        m(x.copy() if c else x)\n",
    "        \n",
    "        dt.append((time_synchronized() - t) * 100)\n",
    "        print('%10.1f%10.0f%10.1fms %-40s' % (o, m.np, dt[-1], m.type))\n",
    "\n",
    "    x = m(x)  # run\n",
    "    y.append(x if m.i in model.save else None)  # save output\n",
    "if profile:\n",
    "    before_dt = sum(dt)\n",
    "    print('before %.1fms total' % sum(dt))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "       0.0         0       0.0ms torch.nn.modules.upsampling.Upsample    \n",
      "       0.0    262656       0.1ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0    131584       0.1ms models.common.Conv                      \n",
      "       0.0    131584       0.1ms models.common.Conv                      \n",
      "       0.0    295168       0.1ms models.common.Conv                      \n",
      "       0.0    147712       0.1ms models.common.Conv                      \n",
      "       0.0    147712       0.1ms models.common.Conv                      \n",
      "       0.0    147712       0.1ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0    262656       0.1ms models.common.Conv                      \n",
      "       0.0     33024       0.0ms models.common.Conv                      \n",
      "       0.0         0       0.0ms torch.nn.modules.upsampling.Upsample    \n",
      "       0.0     65792       0.2ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0     33024       0.1ms models.common.Conv                      \n",
      "       0.0     33024       0.1ms models.common.Conv                      \n",
      "       0.0     73856       0.1ms models.common.Conv                      \n",
      "       0.0     36992       0.1ms models.common.Conv                      \n",
      "       0.0     36992       0.1ms models.common.Conv                      \n",
      "       0.0     36992       0.1ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0     65792       0.2ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.MP                        \n",
      "       0.0     16640       0.0ms models.common.Conv                      \n",
      "       0.0     16640       0.1ms models.common.Conv                      \n",
      "       0.0    147712       0.1ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0    131584       0.1ms models.common.Conv                      \n",
      "       0.0    131584       0.1ms models.common.Conv                      \n",
      "       0.0    295168       0.1ms models.common.Conv                      \n",
      "       0.0    147712       0.1ms models.common.Conv                      \n",
      "       0.0    147712       0.1ms models.common.Conv                      \n",
      "       0.0    147712       0.1ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0    262656       0.2ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.MP                        \n",
      "       0.0     66048       0.0ms models.common.Conv                      \n",
      "       0.0     66048       0.1ms models.common.Conv                      \n",
      "       0.0    590336       0.1ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0    525312       0.1ms models.common.Conv                      \n",
      "       0.0    525312       0.1ms models.common.Conv                      \n",
      "       0.0   1180160       0.1ms models.common.Conv                      \n",
      "       0.0    590336       0.1ms models.common.Conv                      \n",
      "       0.0    590336       0.1ms models.common.Conv                      \n",
      "       0.0    590336       0.1ms models.common.Conv                      \n",
      "       0.0         0       0.0ms models.common.Concat                    \n",
      "       0.0   1049600       0.1ms models.common.Conv                      \n",
      "       0.0    328704       0.4ms models.common.RepConv                   \n",
      "       0.0   1312768       0.4ms models.common.RepConv                   \n",
      "       0.0   5246976       0.4ms models.common.RepConv                   \n",
      "       0.0    457725       0.6ms models.yolo.Detect                      \n",
      "after 5.6ms total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naver1/anaconda3/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## server inference\n",
    "\n",
    "\n",
    "device = select_device(opt.device, batch_size=opt.batch_size)\n",
    "model = attempt_load(opt.weights, map_location=device)  # load FP32 model\n",
    "model.eval()\n",
    "for m in model.model[len(model.model)//2:]:\n",
    "    # print(m)\n",
    "    if m.f != -1:  # if not from previous layer\n",
    "        x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
    "    if isinstance(x, list):\n",
    "        x = [t.to(device) for t in x]\n",
    "    else:\n",
    "        x = x.to(device)\n",
    "    if profile:\n",
    "        c = isinstance(m, (Detect, IDetect, IAuxDetect, IBin))\n",
    "        o = thop.profile(m, inputs=(x.copy() if c else x,), verbose=False)[0] / 1E9 * 2 if thop else 0  # FLOPS\n",
    "        for _ in range(10):\n",
    "            m(x.copy() if c else x)\n",
    "        t = time_synchronized()\n",
    "        # for _ in range(10):\n",
    "        #     m(x.copy() if c else x)\n",
    "        m(x.copy() if c else x)\n",
    "        \n",
    "        dt.append((time_synchronized() - t) * 100)\n",
    "        print('%10.1f%10.0f%10.1fms %-40s' % (o, m.np, dt[-1], m.type))\n",
    "\n",
    "    x = m(x)  # run\n",
    "    y.append(x if m.i in model.save else None)  # save output\n",
    "\n",
    "if profile:\n",
    "    print('after %.1fms total' % (sum(dt) - before_dt))\n",
    "    # print('%.1fms total' % (sum(dt) - before_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
